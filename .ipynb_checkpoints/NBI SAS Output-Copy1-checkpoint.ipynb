{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The current process is to copy the sas data set to jupyter folder to process, \n",
    "\n",
    "* to prevent from using the original file while the original one is being written\n",
    "* need a process to transfer a copy of the file directly from project folder to juypter folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# import libraries\n",
    "# ----------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "# import SAS dataset\n",
    "# ------------------\n",
    "# Please note: the import file can also be a csv file which is converted from the SAS dataset\n",
    "# PLease note: pandas may truncate infinite decimals which might cause the output accuracy might be slightly different than the output from SAS\n",
    "#df = pd.read_sas('patpop_baseline_v1.sas7bdat')\n",
    "#df = pd.read_sas('patpop_ps.sas7bdat')\n",
    "#df = pd.read_sas('patpop_baseline_add.sas7bdat')\n",
    "df = pd.read_sas('patpop_ps_add.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# create data etl rules\n",
    "# ---------------------\n",
    "\n",
    "def age_group(age):\n",
    "    # create age bin\n",
    "    if age >= 18 and age <= 54:\n",
    "        return '18-54'\n",
    "    elif age >= 55 and age <= 64:\n",
    "        return '55-64'\n",
    "    elif age >= 65 and age <= 74:\n",
    "        return '65-74'\n",
    "    else:\n",
    "        return '75+'\n",
    "\n",
    "def sex(x):\n",
    "    # create gender labels\n",
    "    if x == 1:\n",
    "        return 'male'\n",
    "    elif x == 2:\n",
    "        return 'female'\n",
    "    else:\n",
    "        return 'missing'\n",
    "\n",
    "def indicator(x):\n",
    "    # create indicator labels for numeric indicator features\n",
    "    if x == 0:\n",
    "        return 'No'\n",
    "    elif x == 1:\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# apply data etl rules\n",
    "# --------------------\n",
    "\n",
    "# create feature age_group\n",
    "df['age_group'] = df['age'].apply(lambda x: age_group(x))\n",
    "# create feature sex_name\n",
    "df['sex_name'] = df['sex'].apply(lambda x: sex(x))\n",
    "# create feature c_year to get calendar year from index date\n",
    "df['c_year'] = df['index_dt'].apply(lambda x: x.to_pydatetime().year)\n",
    "# use below when using csv file to create c_year\n",
    "#df['c_year'] = df['index_dt'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# create output tables for categorical variables\n",
    "# ----------------------------------------------\n",
    "\n",
    "def cross(ind, col):\n",
    "    '''\n",
    "    purpose: return contigency tables for categorical features\n",
    "    \n",
    "    variable:\n",
    "        ind - the index for the contigency table\n",
    "        col - the column for the contigency table\n",
    "    ''' \n",
    "    return pd.crosstab(index=ind, columns=df[col])\n",
    "\n",
    "def char_std(d, ind):\n",
    "    '''\n",
    "    purpose: return std for categoical features\n",
    "    \n",
    "    variable:\n",
    "        d - the dataframe needs to be used for calculation\n",
    "        ind - the index for the output data frame which is used for merging back to the contigency table\n",
    "    '''\n",
    "    # create p1 and p2 for std calculation\n",
    "    p1 = d.iloc[0,0]/cohort_tab.iloc[0,0]\n",
    "    p2 = d.iloc[0,1]/cohort_tab.iloc[0,1]\n",
    "    \n",
    "    # calculate std\n",
    "    if p1 == 0 and p2 == 0:\n",
    "        _std_data = {'std': '.'}\n",
    "    else:\n",
    "        _std_data = {'std': np.absolute(p1 - p2)/np.sqrt((p1*(1-p1) + p2*(1-p2))/2)}\n",
    "    \n",
    "    return d.join(pd.DataFrame(_std_data, index=[ind])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# create output tables for numeric variables\n",
    "# ------------------------------------------\n",
    "\n",
    "\n",
    "def numeric_tab(var, item, miss_trigger):\n",
    "    '''\n",
    "    purpose: return descriptive tables for numerical features\n",
    "    \n",
    "    variable:\n",
    "        var - the feature needs to be processed\n",
    "        item - the main data frame that has been grouped by cohort\n",
    "        miss_trigger - the trigger for output number of missing values\n",
    "    '''\n",
    "    # define each descriptive statistics\n",
    "    _mea = item.mean().round(2).to_frame().rename(columns={var:var+'_mean'}).transpose()\n",
    "    _s = item.std().round(2).to_frame().rename(columns={var:var+'_std'}).transpose()\n",
    "    _med = item.median().round(2).to_frame().rename(columns={var:var+'_median'}).transpose()\n",
    "    _q25 = item.quantile(0.25,interpolation='midpoint').round(2).to_frame()\n",
    "    _q75 = item.quantile(0.75,interpolation='midpoint').round(2).to_frame()\n",
    "    _min = item.min().round(2).to_frame()\n",
    "    _max = item.max().round(2).to_frame()\n",
    "    _nul = item.apply(lambda x: x.isnull().sum()).to_frame().rename(columns={var:var+'_missing'}).transpose()\n",
    "        \n",
    "    # combine quantiles\n",
    "    _q = _q25.rename(columns={var:var+'_Q1'}).join(_q75.rename(columns={var: var+'_Q3'}))\n",
    "    _q[var+'_Q1_Q3'] = _q[var+'_Q1'].map(str) + '; ' + _q[var+'_Q3'].map(str)\n",
    "    _q = _q.drop([var+'_Q1', var+'_Q3'], axis=1).transpose()\n",
    "    \n",
    "    # combine min and max\n",
    "    _m = _min.rename(columns={var:var+'_min'}).join(_max.rename(columns={var: var+'_max'}))\n",
    "    _m[var+'_min_max'] = _m[var+'_min'].map(str) + '; ' + _m[var+'_max'].map(str)\n",
    "    _m = _m.drop([var+'_min', var+'_max'], axis=1).transpose()\n",
    "\n",
    "    # calculate std\n",
    "    _std_data = {'std': np.absolute(_mea.iloc[0,0] - _mea.iloc[0,1])/np.sqrt((np.square(_s.iloc[0,0]) + np.square(_s.iloc[0,1]))/2)}\n",
    "    _std = pd.DataFrame(_std_data, index=[var+'_mean'])\n",
    "    \n",
    "    # control whether to output number of missing values or not\n",
    "    if miss_trigger == 1:\n",
    "        _df = pd.concat([_mea, _s, _med, _q, _m, _nul])\n",
    "    else:\n",
    "        _df = pd.concat([_mea, _s, _med, _q, _m])\n",
    "    \n",
    "    return _df.join(_std.round(3)).fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# acquire SAS variables for processing \n",
    "# ------------------------------------\n",
    "# this excel file may require proper changes before it can be processed and the rules are as follows:\n",
    "# 1.Record a MACRO for what I'm going to do\n",
    "# 2.Match each tab with corresponding output tables, create new tab if anything's not in the output table like other drugs\n",
    "# 3.Make sure all the variables names are filled in order to output NA correctly\n",
    "# 4.Make sure the output sequence matches\n",
    "# 5.Create type variable to control categorical or numerical output where C stands for categorical and N stands for Numerical\n",
    "\n",
    "sas_lifestyle = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='life_style') # not use this at this moment\n",
    "sas_Diabetes_complications = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='Diabetes complications')\n",
    "sas_other_comorbidity = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='other_comorbidity')\n",
    "sas_other_drugs = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='other_drugs')\n",
    "sas_laboratory = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='laboratory')\n",
    "sas_Prior_concomitant = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='Prior concomitant')\n",
    "sas_resource_utilization = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='resource_utilization')\n",
    "sas_cost = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='cost')\n",
    "\n",
    "sas_var = pd.concat([sas_lifestyle, sas_Diabetes_complications, sas_other_comorbidity, sas_other_drugs,\n",
    "                    sas_laboratory, sas_Prior_concomitant, sas_resource_utilization, sas_cost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guzhao\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# generate output tables\n",
    "# ----------------------\n",
    "# strategy: \n",
    "#    for categorical tables, a dummy data frame will be createed first with index as 'Yes', 'No' and 'Missing', then the values will be filled in\n",
    "#    for numerical tables, the output from the function numeric_tab is immediately usable\n",
    "\n",
    "\n",
    "# prepare excel writer\n",
    "writer = pd.ExcelWriter('NBI_results_psa.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# generate \"Baseline demographics\"\n",
    "cohort_tab = cross('number of patients', 'cohort')\n",
    "age_all = numeric_tab('age', df.groupby(['cohort']).age, 0)\n",
    "age_tab = cross(df['age_group'], 'cohort')\n",
    "sex_tab = char_std(cross(df['sex_name'], 'cohort'), 'female')\n",
    "race_dummy = pd.DataFrame({1.0:['', '', '', ''], 2.0:['', '', '', ''], 'std':['', '', '', '']}, index=['race_Category_1', 'race_Category_2', 'race_Category_3', 'race_Missing'])\n",
    "soc_dummy = pd.DataFrame({1.0:['', '', '', ''], 2.0:['', '', '', ''], 'std':['', '', '', '']}, index=['soc_Low', 'soc_Intermediate', 'soc_High', 'soc_Missing'])\n",
    "year_dummy = pd.DataFrame({1.0:[0, 0, 0], 2.0:[0, 0, 0], 'std':['.', 'NA', 'NA']}, index=['2012', '2013', '2014'])\n",
    "year_tab = cross(df['c_year'], 'cohort')\n",
    "base_tab = pd.concat([cohort_tab, age_all, age_tab, sex_tab, race_dummy, soc_dummy, year_dummy, year_tab])\n",
    "base_tab = base_tab.replace(np.nan, 'NA', regex=True)\n",
    "base_tab.to_excel(writer, sheet_name='baseline')\n",
    "\n",
    "# generate \"output\"\n",
    "output=[]\n",
    "for value, t, s in zip(sas_var['Variable_name'], sas_var['Type'], sas_var['Style']):\n",
    "    if value in df.columns and t == 'C':   \n",
    "        \n",
    "        if s == 'F':\n",
    "            dummy_df = pd.DataFrame({1.0:[0, 0, '.'], 2.0:[0, 0, '.'], 'std':['.', 'NA', 'NA']}, index=['Yes', 'No', 'Missing'])\n",
    "            value_tab = char_std(cross(df[value].apply(lambda x:indicator(x)), 'cohort').iloc[::-1], 'Yes')\n",
    "            new_index = pd.DataFrame({'new_index':[value+'_Yes', value+'_No', value+'_Missing']}, index=['Yes', 'No', 'Missing'])\n",
    "        elif s == 'Y':\n",
    "            dummy_df = pd.DataFrame({1.0:[''], 2.0:[''], 'std':['']}, index=['Yes'])\n",
    "            value_tab = char_std(cross(df[value].apply(lambda x:indicator(x)), 'cohort').iloc[::-1], 'Yes')\n",
    "            if ('Yes' in value_tab.index.values.tolist()):\n",
    "                value_tab = value_tab.loc[['Yes']]\n",
    "            else:\n",
    "                value_tab = pd.DataFrame({1.0:[''], 2.0:[''], 'std':['']}, index=[value+'Yes'])\n",
    "            new_index = pd.DataFrame({'new_index':[value+'_Yes']}, index=['Yes'])\n",
    "        \n",
    "        dummy_df.update(value_tab)\n",
    "        dummy_df.index.name = value   \n",
    "        dummy_df = dummy_df.join(new_index)                        \n",
    "        dummy_df = dummy_df.reset_index(drop=True)\n",
    "        dummy_df = dummy_df.set_index('new_index')    \n",
    "        output.append(dummy_df) \n",
    "    elif value in df.columns and t == 'N':\n",
    "        df_g = df.groupby(['cohort'])\n",
    "        value_tab = numeric_tab(value, df_g[value], 1)\n",
    "        output.append(value_tab)\n",
    "    elif value not in df.columns and t == 'C':\n",
    "        if s == 'F':\n",
    "            value_tab = pd.DataFrame({1.0:['', '', ''], 2.0:['', '', ''], 'std':['', 'NA', 'NA']}, index=[value+'_Yes', value+'_No', value+'_Missing'])\n",
    "        elif s == 'Y':\n",
    "            value_tab = pd.DataFrame({1.0:[''], 2.0:[''], 'std':['']}, index=[value+'Yes'])\n",
    "        \n",
    "        value_tab.index.name = value      \n",
    "        output.append(value_tab)\n",
    "    elif value not in df.columns and t == 'N':\n",
    "        value_tab = pd.DataFrame({1.0:['', '', '', '', '', ''], 2.0:['', '', '', '', '', ''], 'std':['', 'NA', 'NA', 'NA', 'NA', 'NA']}, index=[value+'_mean', value+'_std', value+'_median', value+'_Q1_Q3', value+'_min_max', value+'_missing'])\n",
    "        value_tab.index.name = value    \n",
    "        output.append(value_tab)\n",
    "            \n",
    "output = pd.concat(output)\n",
    "output.to_excel(writer, sheet_name='output')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_pre_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pre_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pre_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pre_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pre_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pre_cost_missing</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_cost_missing</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_CV_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_CV_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_CV_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_CV_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_CV_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_CV_cost_missing</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_no_CV_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_no_CV_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_no_CV_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_no_CV_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_no_CV_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_no_CV_cost_missing</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_cost_missing</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_CV_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_CV_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_CV_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_CV_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_CV_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_CV_cost_missing</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_non_CV_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_non_CV_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_non_CV_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_non_CV_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_non_CV_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_non_CV_cost_missing</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_cost_missing</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_dm_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_dm_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_dm_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_dm_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_dm_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_dm_cost_missing</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_non_dm_cost_mean</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_non_dm_cost_std</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_non_dm_cost_median</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_non_dm_cost_Q1_Q3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_non_dm_cost_min_max</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_non_dm_cost_missing</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         1.0\n",
       "total_pre_cost_mean     None\n",
       "total_pre_cost_std      None\n",
       "total_pre_cost_median   None\n",
       "total_pre_cost_Q1_Q3    None\n",
       "total_pre_cost_min_max  None\n",
       "total_pre_cost_missing     .\n",
       "ip_cost_mean            None\n",
       "ip_cost_std             None\n",
       "ip_cost_median          None\n",
       "ip_cost_Q1_Q3           None\n",
       "ip_cost_min_max         None\n",
       "ip_cost_missing         None\n",
       "ip_CV_cost_mean         None\n",
       "ip_CV_cost_std          None\n",
       "ip_CV_cost_median       None\n",
       "ip_CV_cost_Q1_Q3        None\n",
       "ip_CV_cost_min_max      None\n",
       "ip_CV_cost_missing      None\n",
       "ip_no_CV_cost_mean      None\n",
       "ip_no_CV_cost_std       None\n",
       "ip_no_CV_cost_median    None\n",
       "ip_no_CV_cost_Q1_Q3     None\n",
       "ip_no_CV_cost_min_max   None\n",
       "ip_no_CV_cost_missing   None\n",
       "op_cost_mean            None\n",
       "op_cost_std             None\n",
       "op_cost_median          None\n",
       "op_cost_Q1_Q3           None\n",
       "op_cost_min_max         None\n",
       "op_cost_missing         None\n",
       "op_CV_cost_mean         None\n",
       "op_CV_cost_std          None\n",
       "op_CV_cost_median       None\n",
       "op_CV_cost_Q1_Q3        None\n",
       "op_CV_cost_min_max      None\n",
       "op_CV_cost_missing      None\n",
       "op_non_CV_cost_mean     None\n",
       "op_non_CV_cost_std      None\n",
       "op_non_CV_cost_median   None\n",
       "op_non_CV_cost_Q1_Q3    None\n",
       "op_non_CV_cost_min_max  None\n",
       "op_non_CV_cost_missing  None\n",
       "rx_cost_mean            None\n",
       "rx_cost_std             None\n",
       "rx_cost_median          None\n",
       "rx_cost_Q1_Q3           None\n",
       "rx_cost_min_max         None\n",
       "rx_cost_missing         None\n",
       "rx_dm_cost_mean         None\n",
       "rx_dm_cost_std          None\n",
       "rx_dm_cost_median       None\n",
       "rx_dm_cost_Q1_Q3        None\n",
       "rx_dm_cost_min_max      None\n",
       "rx_dm_cost_missing      None\n",
       "rx_non_dm_cost_mean     None\n",
       "rx_non_dm_cost_std      None\n",
       "rx_non_dm_cost_median   None\n",
       "rx_non_dm_cost_Q1_Q3    None\n",
       "rx_non_dm_cost_min_max  None\n",
       "rx_non_dm_cost_missing  None"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def miss_dot(x):\n",
    "    if x == 0:\n",
    "        return '.'\n",
    "\n",
    "_nul = item.apply(lambda x: x.isnull().sum()).to_frame().rename(columns={var:var+'_missing'}).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
