{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The current process is to copy the sas data set to jupyter folder to process, \n",
    "\n",
    "* to prevent from using the file while the file is being written\n",
    "* need to process to copy the file directly from project folder to juypter folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the SAS file\n",
    "df = pd.read_csv('patpop_ps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create/manipulate features\n",
    "def age_group(age):\n",
    "    # create age group\n",
    "    if age >= 18 and age <= 54:\n",
    "        return '18-54'\n",
    "    elif age >= 55 and age <= 64:\n",
    "        return '55-64'\n",
    "    elif age >= 65 and age <= 74:\n",
    "        return '65-74'\n",
    "    else:\n",
    "        return '75+'\n",
    "\n",
    "def sex(x):\n",
    "    # relabel sex\n",
    "    if x == 1:\n",
    "        return 'male'\n",
    "    elif x == 2:\n",
    "        return 'female'\n",
    "    else:\n",
    "        return 'missing'\n",
    "\n",
    "def indicator(x):\n",
    "    # relabel indicator\n",
    "    if x == 0:\n",
    "        return 'No'\n",
    "    elif x == 1:\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply feature transformation\n",
    "df['age_group'] = df['age'].apply(lambda x: age_group(x))\n",
    "df['sex_name'] = df['sex'].apply(lambda x: sex(x))\n",
    "#df['c_year'] = df['index_dt'].apply(lambda x: x.to_pydatetime().year)\n",
    "df['c_year'] = df['index_dt'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tables for categorical variables\n",
    "def cross(ind, col):\n",
    "    # create contigency table for categorical features\n",
    "    return pd.crosstab(index=ind, columns=df[col])\n",
    "\n",
    "def char_std(d, ind):\n",
    "    # create std for categorical features\n",
    "    p1 = d.iloc[0,0]/cohort_tab.iloc[0,0]\n",
    "    p2 = d.iloc[0,1]/cohort_tab.iloc[0,1]\n",
    "    _std_data = {'std': np.absolute(p1 - p2)/np.sqrt((p1*(1-p1) + p2*(1-p2))/2)}\n",
    "    return d.join(pd.DataFrame(_std_data, index=[ind])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_tab(var, item, miss_trigger):\n",
    "    # generate tables for numeric features\n",
    "    _mea = item.mean().round(2).to_frame().rename(columns={var:var+'_mean'}).transpose()\n",
    "    _s = item.std().round(2).to_frame().rename(columns={var:var+'_std'}).transpose()\n",
    "    _med = item.median().round(2).to_frame().rename(columns={var:var+'_median'}).transpose()\n",
    "    _q25 = item.quantile(0.25,interpolation='midpoint').round(2).to_frame()\n",
    "    _q75 = item.quantile(0.75,interpolation='midpoint').round(2).to_frame()\n",
    "    _min = item.min().round(2).to_frame()\n",
    "    _max = item.max().round(2).to_frame()\n",
    "    _nul = item.apply(lambda x: x.isnull().sum()).to_frame().rename(columns={var:var+'_missing'}).transpose()\n",
    "    \n",
    "\n",
    "    _q = _q25.rename(columns={var:var+'_Q1'}).join(_q75.rename(columns={var: var+'_Q3'}))\n",
    "    _q[var+'_Q1_Q3'] = _q[var+'_Q1'].map(str) + '; ' + _q[var+'_Q3'].map(str)\n",
    "    _q = _q.drop([var+'_Q1', var+'_Q3'], axis=1).transpose()\n",
    "\n",
    "    _m = _min.rename(columns={var:var+'_min'}).join(_max.rename(columns={var: var+'_max'}))\n",
    "    _m[var+'_min_max'] = _m[var+'_min'].map(str) + '; ' + _m[var+'_max'].map(str)\n",
    "    _m = _m.drop([var+'_min', var+'_max'], axis=1).transpose()\n",
    "\n",
    "    _std_data = {'std': np.absolute(_mea.iloc[0,0] - _mea.iloc[0,1])/np.sqrt((np.square(_s.iloc[0,0]) + np.square(_s.iloc[0,1]))/2)}\n",
    "    _std = pd.DataFrame(_std_data, index=[var+'_mean'])\n",
    "    \n",
    "    if miss_trigger == 1:\n",
    "        _df = pd.concat([_mea, _s, _med, _q, _m, _nul])\n",
    "    else:\n",
    "        _df = pd.concat([_mea, _s, _med, _q, _m])\n",
    "    \n",
    "    return _df.join(_std.round(3)).fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1     2  std\n",
       "Yes         7     7  0.0\n",
       "No       5632  5632  NaN\n",
       "Missing     0     0  0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol_tab = char_std(cross(df['Alcohol_abuse'].apply(lambda x:indicator(x)), 'cohort').iloc[::-1], 'Yes')\n",
    "\n",
    "add = pd.DataFrame({1.0:[0], 2.0:[0], 'std':[0]}, index=['Missing'])\n",
    "\n",
    "alcohol_tab.append(add)\n",
    "pd.concat([alcohol_tab, add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BNP_res_mean</th>\n",
       "      <td>182.69</td>\n",
       "      <td>234.39</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNP_res_std</th>\n",
       "      <td>288.07</td>\n",
       "      <td>399.44</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNP_res_median</th>\n",
       "      <td>54.1</td>\n",
       "      <td>55.65</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNP_res_Q1_Q3</th>\n",
       "      <td>15.18; 204.95</td>\n",
       "      <td>17.75; 250.3</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNP_res_min_max</th>\n",
       "      <td>4.1; 1770.5</td>\n",
       "      <td>3.8; 2073.6</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNP_res_missing</th>\n",
       "      <td>5497</td>\n",
       "      <td>5535</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             1             2    std\n",
       "BNP_res_mean            182.69        234.39  0.148\n",
       "BNP_res_std             288.07        399.44     NA\n",
       "BNP_res_median            54.1         55.65     NA\n",
       "BNP_res_Q1_Q3    15.18; 204.95  17.75; 250.3     NA\n",
       "BNP_res_min_max    4.1; 1770.5   3.8; 2073.6     NA\n",
       "BNP_res_missing           5497          5535     NA"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df = pd.DataFrame({1.0:[0, 0, 0], 2.0:[0, 0, 0], 'std':[0, 0, 0]}, index=['Yes', 'No', 'Missing'])\n",
    "new_index = pd.DataFrame({'new_index':['_Yes', '_No', '_Missing']}, index=['Yes', 'No', 'Missing'])\n",
    "dummy_df.update(alcohol_tab)\n",
    "dummy_df=dummy_df.join(new_index)\n",
    "dummy_df=dummy_df.reset_index(drop=True)\n",
    "\n",
    "dummy_df\n",
    "test = numeric_tab('BNP_res', df.groupby(['cohort']).BNP_res, 1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# from SAS variable excel to create generation statement\n",
    "# this sheet may require multiple changes before it can be processed the rules are as follows\n",
    "# 1.Record a MACRO for what I'm going to do\n",
    "# 2.Match each tab with corresponding output tables, create new tab if anything's not in the output table like other drugs\n",
    "# 3.Make sure all the variables names are filled in order to output NA correctly\n",
    "# 4.Make sure the output sequence matches\n",
    "#\n",
    "sas_lifestyle = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='life_style') # not use this at this moment\n",
    "sas_Diabetes_complications = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='Diabetes complications')\n",
    "sas_other_comorbidity = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='other_comorbidity')\n",
    "sas_other_drugs = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='other_drugs')\n",
    "sas_laboratory = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='laboratory')\n",
    "sas_Prior_concomitant = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='Prior concomitant')\n",
    "sas_resource_utilization = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='resource_utilization')\n",
    "sas_cost = pd.read_excel('NBI covariates name 1 .xlsx', sheet_name='cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guzhao\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# generate data frames for categorical features\n",
    "\n",
    "# prepare excel writer\n",
    "writer = pd.ExcelWriter('results.xlsx', engine='xlsxwriter')\n",
    "\n",
    "cohort_tab = cross('number of patients', 'cohort')\n",
    "age_all = numeric_tab('age', df.groupby(['cohort']).age, 0)\n",
    "age_tab = cross(df['age_group'], 'cohort')\n",
    "sex_tab = char_std(cross(df['sex_name'], 'cohort'), 'female')\n",
    "race_dummy = pd.DataFrame({1.0:['NA', 'NA', 'NA', 'NA'], 2.0:['NA', 'NA', 'NA', 'NA'], 'std':['NA', 'NA', 'NA', 'NA']}, index=['race_Category_1', 'race_Category_2', 'race_Category_3', 'race_Missing'])\n",
    "soc_dummy = pd.DataFrame({1.0:['NA', 'NA', 'NA', 'NA'], 2.0:['NA', 'NA', 'NA', 'NA'], 'std':['NA', 'NA', 'NA', 'NA']}, index=['soc_Low', 'soc_Intermediate', 'soc_High', 'soc_Missing'])\n",
    "year_dummy = pd.DataFrame({1.0:[0, 0, 0], 2.0:[0, 0, 0], 'std':[0, 'NA', 'NA']}, index=['2012', '2013', '2014'])\n",
    "year_tab = cross(df['c_year'], 'cohort')\n",
    "base_tab = pd.concat([cohort_tab, age_all, age_tab, sex_tab, race_dummy, soc_dummy, year_dummy, year_tab])\n",
    "base_tab = base_tab.replace(np.nan, 'NA', regex=True)\n",
    "base_tab.to_excel(writer, sheet_name='baseline')\n",
    "\n",
    "\n",
    "lifestyle=[]\n",
    "for value, y in zip(sas_lifestyle['Variable_name'], sas_lifestyle['Type']):\n",
    "    if value in df.columns and y == 'C':\n",
    "        value_tab = char_std(cross(df[value].apply(lambda x:indicator(x)), 'cohort').iloc[::-1], 'Yes')\n",
    "        dummy_df = pd.DataFrame({1.0:[0, 0, 0], 2.0:[0, 0, 0], 'std':[0, 'NA', 'NA']}, index=['Yes', 'No', 'Missing'])\n",
    "        if ('Yes' or 'No' in value_tab.index.values.tolist()):\n",
    "            dummy_df.update(value_tab)\n",
    "            dummy_df.index.name = value\n",
    "            new_index = pd.DataFrame({'new_index':[value+'_Yes', value+'_No', value+'_Missing']}, index=['Yes', 'No', 'Missing'])\n",
    "            dummy_df = dummy_df.join(new_index)                        \n",
    "            dummy_df = dummy_df.reset_index(drop=True)\n",
    "            dummy_df = dummy_df.set_index('new_index')\n",
    "            lifestyle.append(dummy_df)\n",
    "        else:\n",
    "            value_tab = pd.DataFrame({1.0:[0, 0, 0], 2.0:[0, 0, 0], 'std':[0, 'NA', 'NA']}, index=[value+'_Yes', value+'_No', value+'_Missing'])\n",
    "            value_tab.index.name = value\n",
    "            lifestyle.append(value_tab)    \n",
    "    elif value in df.columns and y == 'N':\n",
    "        df_g = df.groupby(['cohort'])\n",
    "        value_tab = numeric_tab(value, df_g[value], 1)\n",
    "        lifestyle.append(value_tab)\n",
    "    elif value not in df.columns and y == 'C':\n",
    "        value_tab = pd.DataFrame({1.0:['NA', 'NA', 'NA'], 2.0:['NA', 'NA', 'NA'], 'std':['NA', 'NA', 'NA']}, index=[value+'_Yes', value+'_No', value+'_Missing'])\n",
    "        value_tab.index.name = value\n",
    "        lifestyle.append(value_tab)\n",
    "    elif value not in df.columns and y == 'N':\n",
    "        value_tab = pd.DataFrame({1.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  2.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  'std':['NA', 'NA', 'NA', 'NA', 'NA', 'NA']}, \n",
    "                                  index=[value+'_mean', value+'_std', value+'_median', value+'_Q1_Q3', value+'_min_max', value+'_missing'])\n",
    "        value_tab.index.name = value    \n",
    "        lifestyle.append(value_tab)\n",
    "        \n",
    "lifestyle = pd.concat(lifestyle)\n",
    "lifestyle.to_excel(writer, sheet_name='lifestyle')\n",
    "\n",
    "\n",
    "Diabetes_complications=[]\n",
    "for value in sas_Diabetes_complications['Variable_name']:\n",
    "    if value in df.columns:\n",
    "        value_tab = char_std(cross(df[value].apply(lambda x:indicator(x)), 'cohort').iloc[::-1], 'Yes')\n",
    "        dummy_df = pd.DataFrame({1.0:[0], 2.0:[0], 'std':[0]}, index=['Yes'])\n",
    "        if ('Yes' in value_tab.index.values.tolist()):\n",
    "            value_tab = value_tab.loc[['Yes']]\n",
    "            dummy_df.update(value_tab)\n",
    "            dummy_df.index.name = value\n",
    "            new_index = pd.DataFrame({'new_index':[value+'_Yes']}, index=['Yes'])\n",
    "            dummy_df = dummy_df.join(new_index)                        \n",
    "            dummy_df = dummy_df.reset_index(drop=True)\n",
    "            dummy_df = dummy_df.set_index('new_index')\n",
    "            Diabetes_complications.append(dummy_df)\n",
    "        else:\n",
    "            value_tab = pd.DataFrame({1.0:[0], 2.0:[0], 'std':[0]}, index=[value+'Yes'])\n",
    "            value_tab.index.name = value\n",
    "            Diabetes_complications.append(value_tab)\n",
    "    else:\n",
    "        value_tab = pd.DataFrame({1.0:['NA'], 2.0:['NA'], 'std':['NA']}, index=[value+'Yes'])\n",
    "        value_tab.index.name = value    \n",
    "        Diabetes_complications.append(value_tab)    \n",
    "\n",
    "Diabetes_complications = pd.concat(Diabetes_complications)\n",
    "Diabetes_complications.to_excel(writer, sheet_name='Diabetes_complications')\n",
    "\n",
    "other_comorbidity=[]\n",
    "for value in sas_other_comorbidity['Variable_name']:\n",
    "    if value in df.columns:\n",
    "        value_tab = char_std(cross(df[value].apply(lambda x:indicator(x)), 'cohort').iloc[::-1], 'Yes')\n",
    "        dummy_df = pd.DataFrame({1.0:[0], 2.0:[0], 'std':[0]}, index=['Yes'])\n",
    "        if ('Yes' in value_tab.index.values.tolist()):\n",
    "            value_tab = value_tab.loc[['Yes']]\n",
    "            dummy_df.update(value_tab)\n",
    "            dummy_df.index.name = value\n",
    "            new_index = pd.DataFrame({'new_index':[value+'_Yes']}, index=['Yes'])\n",
    "            dummy_df = dummy_df.join(new_index)                        \n",
    "            dummy_df = dummy_df.reset_index(drop=True)\n",
    "            dummy_df = dummy_df.set_index('new_index')\n",
    "            other_comorbidity.append(dummy_df) \n",
    "        else:\n",
    "            value_tab = pd.DataFrame({1.0:[0], 2.0:[0], 'std':[0]}, index=[value+'Yes'])\n",
    "            value_tab.index.name = value\n",
    "            other_comorbidity.append(value_tab) \n",
    "    else:\n",
    "        value_tab = pd.DataFrame({1.0:['NA'], 2.0:['NA'], 'std':['NA']}, index=[value+'Yes'])\n",
    "        value_tab.index.name = value\n",
    "        other_comorbidity.append(value_tab)   \n",
    "\n",
    "other_comorbidity = pd.concat(other_comorbidity)\n",
    "other_comorbidity.to_excel(writer, sheet_name='other_comorbidity')\n",
    "\n",
    "\n",
    "laboratory=[]\n",
    "for value in sas_laboratory['Variable_name_res']:\n",
    "    if value in df.columns:\n",
    "        df_g = df.groupby(['cohort'])\n",
    "        value_tab = numeric_tab(value, df_g[value], 1)\n",
    "        laboratory.append(value_tab)  \n",
    "    else:\n",
    "        value_tab = pd.DataFrame({1.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  2.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  'std':['NA', 'NA', 'NA', 'NA', 'NA', 'NA']}, \n",
    "                                  index=[value+'_mean', value+'_std', value+'_median', value+'_Q1_Q3', value+'_min_max', value+'_missing'])\n",
    "        value_tab.index.name = value    \n",
    "        laboratory.append(value_tab)    \n",
    "\n",
    "laboratory = pd.concat(laboratory)\n",
    "laboratory.to_excel(writer, sheet_name='laboratory')\n",
    "\n",
    "\n",
    "other_drugs=[]\n",
    "for value in sas_other_drugs['Variable_name']:\n",
    "    if value in df.columns:\n",
    "        value_tab = char_std(cross(df[value].apply(lambda x:indicator(x)), 'cohort').iloc[::-1], 'Yes')\n",
    "        dummy_df = pd.DataFrame({1.0:[0], 2.0:[0], 'std':[0]}, index=['Yes'])\n",
    "        if ('Yes' in value_tab.index.values.tolist()):\n",
    "            value_tab = value_tab.loc[['Yes']]\n",
    "            dummy_df.update(value_tab)\n",
    "            dummy_df.index.name = value\n",
    "            new_index = pd.DataFrame({'new_index':[value+'_Yes']}, index=['Yes'])\n",
    "            dummy_df = dummy_df.join(new_index)                        \n",
    "            dummy_df = dummy_df.reset_index(drop=True)\n",
    "            dummy_df = dummy_df.set_index('new_index')\n",
    "            other_drugs.append(dummy_df)  \n",
    "        else:\n",
    "            value_tab = pd.DataFrame({1.0:[0], 2.0:[0], 'std':[0]}, index=[value+'_Yes'])\n",
    "            value_tab.index.name = value\n",
    "            other_drugs.append(value_tab)  \n",
    "\n",
    "    else:\n",
    "        value_tab = pd.DataFrame({1.0:['NA'], 2.0:['NA'], 'std':['NA']}, index=[value+'_Yes'])\n",
    "        value_tab.index.name = value\n",
    "        other_drugs.append(value_tab)  \n",
    "\n",
    "other_drugs = pd.concat(other_drugs)\n",
    "other_drugs.to_excel(writer, sheet_name='other_drugs')\n",
    "\n",
    "\n",
    "Prior_concomitant=[]\n",
    "for value, y in zip(sas_Prior_concomitant['variable_name'], sas_Prior_concomitant['Type']):\n",
    "    if value in df.columns and y == 'C':\n",
    "        value_tab = char_std(cross(df[value].apply(lambda x:indicator(x)), 'cohort').iloc[::-1], 'Yes')\n",
    "        dummy_df = pd.DataFrame({1.0:[0], 2.0:[0], 'std':[0]}, index=['Yes'])\n",
    "        if ('Yes' in value_tab.index.values.tolist()):\n",
    "            value_tab = value_tab.loc[['Yes']]\n",
    "            dummy_df.update(value_tab)\n",
    "            dummy_df.index.name = value\n",
    "            new_index = pd.DataFrame({'new_index':[value+'_Yes']}, index=['Yes'])\n",
    "            dummy_df = dummy_df.join(new_index)                        \n",
    "            dummy_df = dummy_df.reset_index(drop=True)\n",
    "            dummy_df = dummy_df.set_index('new_index')\n",
    "            Prior_concomitant.append(dummy_df)\n",
    "        else:\n",
    "            value_tab = pd.DataFrame({1.0:[0], 2.0:[0], 'std':[0]}, index=[value+'_Yes'])\n",
    "            value_tab.index.name = value\n",
    "            Prior_concomitant.append(value_tab)\n",
    "    elif value in df.columns and y == 'N':\n",
    "        df_g = df.groupby(['cohort'])\n",
    "        value_tab = numeric_tab(value, df_g[value], 0)\n",
    "        Prior_concomitant.append(value_tab)\n",
    "    elif value not in df.columns and y == 'C':\n",
    "        value_tab = pd.DataFrame({1.0:['NA'], 2.0:['NA'], 'std':['NA']}, index=[value+'_Yes'])\n",
    "        value_tab.index.name = value\n",
    "        Prior_concomitant.append(value_tab)\n",
    "    elif value not in df.columns and y == 'N':\n",
    "        value_tab = pd.DataFrame({1.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  2.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  'std':['NA', 'NA', 'NA', 'NA', 'NA', 'NA']}, \n",
    "                                  index=['_mean', '_std', '_median', '_Q1_Q3', '_min_max', '_missing'])\n",
    "        value_tab.index.name = value    \n",
    "        Prior_concomitant.append(value_tab)  \n",
    "\n",
    "Prior_concomitant = pd.concat(Prior_concomitant)\n",
    "Prior_concomitant.to_excel(writer, sheet_name='Prior_concomitant')\n",
    "\n",
    "\n",
    "resource_utilization=[]\n",
    "for value, y in zip(sas_resource_utilization['variable_name'], sas_resource_utilization['Type']):\n",
    "    if value in df.columns and y == 'C':\n",
    "        value_tab = char_std(cross(df[value].apply(lambda x:indicator(x)), 'cohort').iloc[::-1], 'Yes')\n",
    "        dummy_df = pd.DataFrame({1.0:[0, 0, 0], 2.0:[0, 0, 0], 'std':[0, 'NA', 'NA']}, index=['Yes', 'No', 'Missing'])\n",
    "        if ('Yes' or 'No' in value_tab.index.values.tolist()):\n",
    "            dummy_df.update(value_tab)\n",
    "            dummy_df.index.name = value\n",
    "            new_index = pd.DataFrame({'new_index':[value+'_Yes', value+'_No', value+'_Missing']}, index=['Yes', 'No', 'Missing'])\n",
    "            dummy_df = dummy_df.join(new_index)                        \n",
    "            dummy_df = dummy_df.reset_index(drop=True)\n",
    "            dummy_df = dummy_df.set_index('new_index')\n",
    "            resource_utilization.append(dummy_df)\n",
    "        else:\n",
    "            value_tab = pd.DataFrame({1.0:[0, 0, 0], 2.0:[0, 0, 0], 'std':[0, 0, 0]}, index=[value+'_Yes', value+'_No', value+'_Missing'])\n",
    "            value_tab.index.name = value\n",
    "            resource_utilization.append(value_tab)    \n",
    "    elif value in df.columns and y == 'N':\n",
    "        df_g = df.groupby(['cohort'])\n",
    "        value_tab = numeric_tab(value, df_g[value], 1)\n",
    "        resource_utilization.append(value_tab)\n",
    "    elif value not in df.columns and y == 'C':\n",
    "        value_tab = pd.DataFrame({1.0:['NA', 'NA', 'NA'], 2.0:['NA', 'NA', 'NA'], 'std':['NA', 'NA', 'NA']}, index=[value+'_Yes', value+'_No', value+'_Missing'])\n",
    "        value_tab.index.name = value\n",
    "        resource_utilization.append(value_tab)\n",
    "    elif value not in df.columns and y == 'N':\n",
    "        value_tab = pd.DataFrame({1.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  2.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  'std':['NA', 'NA', 'NA', 'NA', 'NA', 'NA']}, \n",
    "                                  index=[value+'_mean', value+'_std', value+'_median', value+'_Q1_Q3', value+'_min_max', value+'_missing'])\n",
    "        value_tab.index.name = value    \n",
    "        resource_utilization.append(value_tab)\n",
    "        \n",
    "resource_utilization = pd.concat(resource_utilization)\n",
    "resource_utilization.to_excel(writer, sheet_name='resource_utilization')\n",
    "\n",
    "\n",
    "cost=[]\n",
    "for value in sas_cost['variable_name']:\n",
    "    if value in df.columns:\n",
    "        df_g = df.groupby(['cohort'])\n",
    "        value_tab = numeric_tab(value, df_g[value], 1)\n",
    "        cost.append(value_tab)  \n",
    "    else:\n",
    "        value_tab = pd.DataFrame({1.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  2.0:['NA', 'NA', 'NA', 'NA', 'NA', 'NA'], \n",
    "                                  'std':['NA', 'NA', 'NA', 'NA', 'NA', 'NA']}, \n",
    "                                  index=[value+'_mean', value+'_std', value+'_median', value+'_Q1_Q3', value+'_min_max', value+'_missing'])\n",
    "        value_tab.index.name = value    \n",
    "        cost.append(value_tab)    \n",
    "\n",
    "cost = pd.concat(cost)\n",
    "cost.to_excel(writer, sheet_name='cost')\n",
    "\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1.25\n"
     ]
    }
   ],
   "source": [
    "test = np.array([1.25, 2.35, 0, 4.35, 5.35])\n",
    "print(type(test))\n",
    "print(np.quantile(test, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_tab():\n",
    "    return df.groupby(['cohort']).age.isnull().sum().to_frame().rename(columns={'age': 'age_mean'}).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Cannot access callable attribute 'isnull' of 'SeriesGroupBy' objects, try using the 'apply' method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-240-d7845c842f89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_tab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-239-dac947bae15a>\u001b[0m in \u001b[0;36mnumeric_tab\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnumeric_tab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cohort'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'age_mean'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         raise AttributeError(\"%r object has no attribute %r\" %\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_make_wrapper\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    568\u001b[0m                    \"using the 'apply' method\".format(kind, name,\n\u001b[0;32m    569\u001b[0m                                                      type(self).__name__))\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_group_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Cannot access callable attribute 'isnull' of 'SeriesGroupBy' objects, try using the 'apply' method"
     ]
    }
   ],
   "source": [
    "test = numeric_tab()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cohort</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HbA1c_res_missing</th>\n",
       "      <td>5050</td>\n",
       "      <td>5171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cohort              1.0   2.0\n",
       "HbA1c_res_missing  5050  5171"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['cohort']).HbA1c_res.apply(lambda x: x.isnull().sum()).to_frame().rename(columns={'HbA1c_res':'HbA1c_res_missing'}).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
